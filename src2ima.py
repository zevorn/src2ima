import os
import shutil
import click
import hashlib
import gc
import psutil
import concurrent.futures
from functools import partial
from pygments import highlight
from pygments.lexers import get_lexer_for_filename, TextLexer, get_lexer_by_name
from pygments.formatters import HtmlFormatter
from pygments.util import ClassNotFound
import markdown2
from jinja2 import Environment, FileSystemLoader

# é…ç½®é¡¹
DEFAULT_OUTPUT_DIR = "./output"
IGNORE_PATTERNS = [
    # ç›®å½•ï¼ˆä»¥/ç»“å°¾è¡¨ç¤ºç›®å½•ï¼‰
    ".git/", ".github/", "node_modules/", "__pycache__/",
    ".vscode/", ".cache/", "build/", ".sdk/", "dist/", "bin/",
    "pc-bios/", "rust/target/",
    # æ–‡ä»¶æ‰©å±•åï¼ˆä»¥.å¼€å¤´ï¼‰
    ".bin", ".rom", ".bz2", ".gz", ".zip", ".tar", ".7z",
    ".out", ".o", ".so", ".dll", ".pyc", ".pyo", ".patch",
    ".png", ".jpg", ".jpeg", ".gif", ".bmp", ".ico",
    ".pdf", ".docx", ".xlsx", ".pptx",
    # ç‰¹å®šæ–‡ä»¶å
    ".gdb_history", ".clang-format", ".git-submodule-status",
    "Makefile", "makefile", "README", "LICENSE"
]
HIGHLIGHT_THEME = "github-dark"  # æš—è‰²ä¸»é¢˜
TEMPLATE_DIR = "./templates"
MAX_PATH_LENGTH = 255
BATCH_SIZE = 200  # æ¯æ‰¹å¤„ç†çš„æ–‡ä»¶æ•°é‡
MAX_FILE_SIZE = 10 * 1024 * 1024  # 10MBï¼Œå¤§äºæ­¤çš„æ–‡ä»¶å°†è¢«è·³è¿‡
MERGED_FILE_SIZE_LIMIT = 9.5 * 1024 * 1024  # åˆå¹¶æ–‡ä»¶çš„å¤§å°é™åˆ¶9.5MiB
MEMORY_THRESHOLD = 0.85  # å†…å­˜ä½¿ç”¨é˜ˆå€¼ï¼ˆ80%ï¼‰
MAX_WORKERS = None  # æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°
MAX_DIRECTORY_DEPTH = 5  # æœ€å†…å±‚æ–‡ä»¶å¤¹çš„æ·±åº¦ï¼Œæ­¤æ·±åº¦çš„æ–‡ä»¶å¤¹åŠå…¶æ‰€æœ‰å­å†…å®¹å°†è¢«åˆå¹¶
TEXT_CHARS = bytes([7, 8, 9, 10, 12, 13, 27]) + \
    bytes(range(0x20, 0x100))  # æ–‡æœ¬æ–‡ä»¶ç‰¹å¾å­—èŠ‚


def get_optimal_workers():
    """æ ¹æ®ç³»ç»Ÿèµ„æºè®¡ç®—æœ€ä½³å·¥ä½œçº¿ç¨‹æ•°"""
    cpu_count = os.cpu_count() or 4
    mem_gb = psutil.virtual_memory().total / (1024 **3)
    
    # å†…å­˜è¶Šå¤šï¼Œå…è®¸çš„çº¿ç¨‹æ•°è¶Šå¤š
    if mem_gb >= 16:
        return max(8, cpu_count * 4)
    elif mem_gb >= 8:
        return max(4, cpu_count * 2)
    else:
        return max(2, cpu_count)


def get_directory_depth(path):
    """è·å–ç›®å½•æ·±åº¦"""
    path_parts = [part for part in path.split(os.sep) if part]
    return len(path_parts)


def is_target_directory(path, repo_root):
    """åˆ¤æ–­æ˜¯å¦ä¸ºç›®æ ‡æ·±åº¦çš„ç›®å½•ï¼ˆéœ€è¦åˆå¹¶å…¶æ‰€æœ‰å†…å®¹ï¼‰"""
    if not os.path.isdir(path):
        return False
    
    # è®¡ç®—ç›¸å¯¹äºä»“åº“æ ¹ç›®å½•çš„æ·±åº¦
    rel_path = os.path.relpath(path, repo_root)
    depth = get_directory_depth(rel_path)
    
    # ä»…å½“ç›®å½•æ·±åº¦ç­‰äºMAX_DIRECTORY_DEPTHæ—¶è§†ä¸ºç›®æ ‡ç›®å½•
    return depth == MAX_DIRECTORY_DEPTH


def collect_all_files_in_directory(dir_path):
    """æ”¶é›†ç›®å½•ä¸­æ‰€æœ‰æ–‡ä»¶ï¼ˆåŒ…æ‹¬å­ç›®å½•ä¸­çš„æ–‡ä»¶ï¼‰"""
    all_files = []
    stack = [dir_path]
    
    while stack:
        current_path = stack.pop()
        try:
            with os.scandir(current_path) as entries:
                for entry in entries:
                    try:
                        if entry.is_dir(follow_symlinks=False):
                            # é€’å½’å¤„ç†å­ç›®å½•
                            if not should_ignore(entry.path):
                                stack.append(entry.path)
                        else:
                            # æ”¶é›†æ–‡ä»¶
                            if not should_ignore(entry.path):
                                file_size = entry.stat().st_size
                                if file_size <= MAX_FILE_SIZE:
                                    all_files.append((entry.path, file_size))
                                else:
                                    rel_path = os.path.relpath(entry.path, dir_path)
                                    click.echo(f"â­ï¸ è·³è¿‡è¿‡å¤§æ–‡ä»¶ ({file_size//1024//1024}MB): {rel_path}")
                    except Exception as e:
                        click.echo(f"âš ï¸ è®¿é—®{entry.path}æ—¶å‡ºé”™: {str(e)[:30]}")
                        continue
        except PermissionError:
            click.echo(f"ğŸš« æ²¡æœ‰æƒé™è®¿é—®ç›®å½•: {current_path}")
            continue
        except Exception as e:
            click.echo(f"âš ï¸ å¤„ç†ç›®å½•{current_path}æ—¶å‡ºé”™: {str(e)[:30]}")
            continue
    
    return all_files


def collect_target_directories(repo_path):
    """æ”¶é›†æ‰€æœ‰è¾¾åˆ°ç›®æ ‡æ·±åº¦çš„ç›®å½•"""
    target_dirs = {}
    stack = [repo_path]

    while stack:
        current_dir = stack.pop()
        try:
            # æ£€æŸ¥å½“å‰ç›®å½•æ˜¯å¦ä¸ºç›®æ ‡æ·±åº¦ç›®å½•
            if is_target_directory(current_dir, repo_path):
                # æ”¶é›†è¯¥ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶ï¼ˆåŒ…æ‹¬å­ç›®å½•ï¼‰
                all_files = collect_all_files_in_directory(current_dir)
                if all_files:  # åªä¿ç•™æœ‰å¯å¤„ç†æ–‡ä»¶çš„ç›®å½•
                    target_dirs[current_dir] = all_files
                continue  # ç›®æ ‡ç›®å½•ä¸å†é€’å½’å¤„ç†å…¶å­ç›®å½•
            
            # ç»§ç»­æ‰«ææ›´æ·±çš„ç›®å½•
            with os.scandir(current_dir) as entries:
                for entry in entries:
                    try:
                        if entry.is_dir(follow_symlinks=False) and not should_ignore(entry.path):
                            stack.append(entry.path)
                    except Exception as e:
                        click.echo(f"âš ï¸ è®¿é—®{entry.path}æ—¶å‡ºé”™: {str(e)[:30]}")
                        continue
        except PermissionError:
            click.echo(f"ğŸš« æ²¡æœ‰æƒé™è®¿é—®ç›®å½•: {current_dir}")
            continue
        except Exception as e:
            click.echo(f"âš ï¸ å¤„ç†ç›®å½•{current_dir}æ—¶å‡ºé”™: {str(e)[:30]}")
            continue

    return target_dirs


def is_binary_file(file_path, sample_size=1024):
    """åˆ¤æ–­æ–‡ä»¶æ˜¯å¦ä¸ºäºŒè¿›åˆ¶æ–‡ä»¶"""
    if not os.path.isfile(file_path) or os.path.islink(file_path):
        return True

    try:
        with open(file_path, 'rb') as f:
            sample = f.read(sample_size)

        if not sample:
            return False

        return bool(sample.translate(None, TEXT_CHARS))
    except Exception:
        return True


def get_memory_usage():
    """è·å–å½“å‰è¿›ç¨‹å†…å­˜ä½¿ç”¨ç‡ï¼ˆç™¾åˆ†æ¯”ï¼‰"""
    return psutil.Process(os.getpid()).memory_percent()


def wait_for_memory():
    """ç­‰å¾…å†…å­˜ä½¿ç”¨ç‡é™è‡³é˜ˆå€¼ä»¥ä¸‹"""
    while get_memory_usage() > MEMORY_THRESHOLD * 100:
        current_usage = get_memory_usage()
        click.echo(f"âš ï¸ å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ ({current_usage:.1f}%), ç­‰å¾…é‡Šæ”¾...")
        gc.collect()  # å¼ºåˆ¶åƒåœ¾å›æ”¶
        psutil.sleep(1)


def should_ignore(path):
    """åˆ¤æ–­è·¯å¾„æ˜¯å¦åº”è¯¥è¢«å¿½ç•¥"""
    path_lower = path.lower()
    
    # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
    for pattern in IGNORE_PATTERNS:
        if pattern.startswith('.') and len(pattern) > 1 and path_lower.endswith(pattern):
            return True
    
    # æ£€æŸ¥ç›®å½•
    path_parts = path.split(os.sep)
    for pattern in IGNORE_PATTERNS:
        if pattern.endswith('/'):
            dir_name = pattern.rstrip('/')
            if dir_name in path_parts:
                return True
    
    # æ£€æŸ¥æ–‡ä»¶å
    filename = os.path.basename(path)
    for pattern in IGNORE_PATTERNS:
        if not pattern.startswith('.') and not pattern.endswith('/') and filename == pattern:
            return True
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºäºŒè¿›åˆ¶æ–‡ä»¶
    return os.path.isfile(path) and is_binary_file(path)


def get_safe_formatter(theme, output_format):
    """è·å–å®‰å…¨çš„ä»£ç æ ¼å¼åŒ–å™¨å¹¶å¸¦æœ‰ç¼“å­˜æœºåˆ¶"""
    cache_key = f"{theme}_{output_format}"
    if not hasattr(get_safe_formatter, "_cache"):
        get_safe_formatter._cache = {}

    if cache_key not in get_safe_formatter._cache:
        try:
            formatter = HtmlFormatter(style=theme, linenos=True)
        except ClassNotFound:
            click.warning(f"âš ï¸ é«˜äº®ä¸»é¢˜'{theme}'ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤ä¸»é¢˜")
            formatter = HtmlFormatter(style="default", linenos=True)
        get_safe_formatter._cache[cache_key] = formatter

    return get_safe_formatter._cache[cache_key]


def validate_local_repo(local_path):
    """éªŒè¯æœ¬åœ°ä»“åº“è·¯å¾„çš„æœ‰æ•ˆæ€§"""
    local_path = os.path.abspath(local_path)
    if not os.path.exists(local_path):
        raise ValueError(f"è·¯å¾„ä¸å­˜åœ¨: {local_path}")
    if not os.path.isdir(local_path):
        raise ValueError(f"ä¸æ˜¯ç›®å½•: {local_path}")
    return local_path, os.path.basename(local_path)


def shorten_long_path(original_path, max_length, output_format):
    """ç¼©çŸ­è¿‡é•¿çš„æ–‡ä»¶è·¯å¾„ï¼Œä¿ç•™åŸå§‹æ‰©å±•åå¹¶æ·»åŠ æ–°æ ¼å¼åç¼€"""
    if len(original_path) <= max_length:
        return original_path

    dir_name = os.path.dirname(original_path)
    file_name = os.path.basename(original_path)

    # ä¿ç•™åŸå§‹æ–‡ä»¶åå’Œæ‰©å±•åï¼Œåªåœ¨æœ«å°¾æ·»åŠ æ ¼å¼åç¼€
    hash_suffix = hashlib.md5(original_path.encode()).hexdigest()[:6]
    base_name = os.path.splitext(file_name)[0]
    original_ext = os.path.splitext(file_name)[1]
    new_file_name = f"{base_name}_{hash_suffix}{original_ext}.{output_format}"

    return os.path.join(dir_name, new_file_name)


def estimate_content_size(content, output_format):
    """ä¼°è®¡å†…å®¹å†™å…¥ç£ç›˜æ—¶çš„å­—èŠ‚å¤§å°"""
    if output_format == 'html':
        return len(content.encode('utf-8')) * 1.2  # ç²—ç•¥ä¼°è®¡HTMLçš„é¢å¤–å¼€é”€
    return len(content.encode('utf-8'))  # Markdownå¤§è‡´æ˜¯1:1


def read_file_content(file_path):
    """è¯»å–æ–‡ä»¶å†…å®¹ï¼Œä½¿ç”¨ä¼˜åŒ–çš„åˆ†å—è¯»å–"""
    try:
        with open(file_path, 'r', encoding='utf-8', errors='replace') as f:
            return f.read()
    except UnicodeDecodeError:
        with open(file_path, 'r', encoding='latin-1') as f:
            return f.read()


def process_target_directory(dir_path, repo_root, output_dir, formatter, output_format):
    """å¤„ç†ç›®æ ‡æ·±åº¦ç›®å½•ï¼Œåˆå¹¶å…¶æ‰€æœ‰æ–‡ä»¶ï¼ˆåŒ…æ‹¬å­ç›®å½•ä¸­çš„æ–‡ä»¶ï¼‰"""
    try:
        rel_dir_path = os.path.relpath(dir_path, repo_root)
        dir_name = os.path.basename(dir_path)
        
        # è·å–è¯¥ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶ï¼ˆå·²åœ¨æ”¶é›†é˜¶æ®µå®Œæˆï¼‰
        files_with_size = collect_all_files_in_directory(dir_path)
        if not files_with_size:
            return (False, f"ğŸ“‚ ç›®æ ‡ç›®å½•{rel_dir_path}ä¸­æ²¡æœ‰å¯å¤„ç†çš„æ–‡ä»¶")

        # æŒ‰æ–‡ä»¶å¤§å°æ’åºä»¥ä¼˜åŒ–æ‹†åˆ†
        files_with_size.sort(key=lambda x: x[1])
        files_in_dir = [f[0] for f in files_with_size]
        
        # ç”ŸæˆåŸºç¡€è¾“å‡ºè·¯å¾„
        output_rel_path = os.path.dirname(rel_dir_path)
        base_output_file_name = f"{dir_name}"
        base_output_path = os.path.join(output_dir, output_rel_path, base_output_file_name)
        os.makedirs(os.path.dirname(base_output_path), exist_ok=True)

        # å‡†å¤‡å†…å®¹éƒ¨åˆ†
        sections = []
        current_section = {"content": "", "size_estimate": 0, "files_included": []}
        
        if output_format == 'html':
            section_header = f"<h1>ç›®å½•å†…å®¹: {rel_dir_path}ï¼ˆç¬¬{{part_number}}éƒ¨åˆ†ï¼‰</h1>\n"
            highlight_css = formatter.get_style_defs(".highlight")
        else:  # markdown
            section_header = f"# ç›®å½•å†…å®¹: {rel_dir_path}ï¼ˆç¬¬{{part_number}}éƒ¨åˆ†ï¼‰\n\n"

        # è®¡ç®—æ ‡é¢˜å¤§å°
        header_size = estimate_content_size(section_header.replace("{{part_number}}", "1"), output_format)
        
        # å¤„ç†æ¯ä¸ªæ–‡ä»¶å¹¶æ·»åŠ åˆ°éƒ¨åˆ†ä¸­
        for file_path in files_in_dir:
            # è®¡ç®—æ–‡ä»¶ç›¸å¯¹äºç›®æ ‡ç›®å½•çš„è·¯å¾„ï¼Œä¿ç•™å®Œæ•´çš„å­ç›®å½•ç»“æ„ä¿¡æ¯
            rel_file_path = os.path.relpath(file_path, dir_path)
            full_rel_path = os.path.join(rel_dir_path, rel_file_path)
            
            # è¯»å–æ–‡ä»¶å†…å®¹
            content = read_file_content(file_path)

            # å¤„ç†å•ä¸ªæ–‡ä»¶å†…å®¹
            ext = os.path.splitext(file_path)[1].lower()
            file_ext = ext.lstrip('.') if ext else 'txt'
            file_content = ""

            if output_format == 'html':
                # æ·»åŠ æ–‡ä»¶è·¯å¾„æ ‡é¢˜ï¼ˆåŒ…å«å®Œæ•´çš„å­ç›®å½•ç»“æ„ï¼‰
                file_content += f"<h2>æ–‡ä»¶è·¯å¾„: {full_rel_path}</h2>\n"
                
                if ext == ".md":
                    # è½¬æ¢Markdownä¸ºHTML
                    html_content = markdown2.markdown(
                        content,
                        extras=["fenced-code-blocks", "tables"]
                    )
                    file_content += f"<div class='file-content'>{html_content}</div>\n"
                else:
                    # è½¬æ¢ä»£ç æ–‡ä»¶ä¸ºå¸¦é«˜äº®çš„HTML
                    try:
                        lexer = get_lexer_for_filename(file_path)
                    except Exception:
                        lexer = TextLexer()
                    html_content = highlight(content, lexer, formatter)
                    file_content += f"<div class='file-content'>{html_content}</div>\n"

            else:  # markdown
                # æ·»åŠ æ–‡ä»¶è·¯å¾„æ ‡é¢˜ï¼ˆåŒ…å«å®Œæ•´çš„å­ç›®å½•ç»“æ„ï¼‰
                file_content += f"## æ–‡ä»¶è·¯å¾„: {full_rel_path}\n\n"
                
                if ext == ".md":
                    # ä¿ç•™Markdownæ–‡ä»¶çš„åŸå§‹å†…å®¹
                    file_content += f"{content}\n\n"
                else:
                    # ç”ŸæˆMarkdownä»£ç å—
                    try:
                        lexer = get_lexer_for_filename(file_path)
                        lexer_name = lexer.aliases[0] if lexer.aliases else lexer.name.lower()
                    except Exception:
                        try:
                            lexer = get_lexer_by_name(file_ext)
                            lexer_name = file_ext
                        except Exception:
                            lexer_name = 'text'

                    # è½¬ä¹‰ä»£ç ä¸­çš„åå¼•å·
                    escaped_content = content.replace('`', '\\`')
                    file_content += f"``` {lexer_name}\n{escaped_content}\n```\n\n"

            # ä¼°è®¡å¤§å°å¹¶ç®¡ç†éƒ¨åˆ†
            file_content_size = estimate_content_size(file_content, output_format)
            
            if current_section["size_estimate"] + file_content_size > MERGED_FILE_SIZE_LIMIT:
                if current_section["size_estimate"] > 0:
                    sections.append(current_section)
                current_section = {
                    "content": file_content,
                    "size_estimate": header_size + file_content_size,
                    "files_included": [full_rel_path]
                }
            else:
                current_section["content"] += file_content
                current_section["size_estimate"] += file_content_size
                current_section["files_included"].append(full_rel_path)

        if current_section["size_estimate"] > 0:
            sections.append(current_section)

        # å†™å…¥æ‰€æœ‰éƒ¨åˆ†
        results = []
        for i, section in enumerate(sections, 1):
            if len(sections) > 1:
                output_file_name = f"{base_output_file_name}_part{i}.{output_format}"
            else:
                output_file_name = f"{base_output_file_name}.{output_format}"
                
            output_path = os.path.join(output_dir, output_rel_path, output_file_name)
            output_path = shorten_long_path(output_path, MAX_PATH_LENGTH, output_format)

            if output_format == 'html':
                formatted_header = section_header.replace("{{part_number}}", str(i) if len(sections) > 1 else "1")
                final_content = file_template.render(
                    title=f"{rel_dir_path}ï¼ˆç¬¬{i}éƒ¨åˆ†ï¼‰" if len(sections) > 1 else rel_dir_path,
                    rel_path=rel_dir_path,
                    content=formatted_header + section["content"],
                    highlight_css=highlight_css
                )
            else:
                formatted_header = section_header.replace("{{part_number}}", str(i) if len(sections) > 1 else "1")
                final_content = formatted_header + section["content"]

            # å†™å…¥æ–‡ä»¶
            with open(output_path, "w", encoding="utf-8") as f:
                f.write(final_content)

            results.append((output_path, section["files_included"]))

        if len(sections) > 1:
            message = f"ğŸŸ¢ ç›®æ ‡ç›®å½•æ‹†åˆ†ä¸º{len(sections)}ä¸ªéƒ¨åˆ†ï¼ˆ{output_format}ï¼‰: {rel_dir_path}"
        else:
            message = f"ğŸŸ¢ ç›®æ ‡ç›®å½•åˆå¹¶ä¸º{output_format}: {rel_dir_path}"

        return (True, message, results)

    except Exception as e:
        rel_path = os.path.relpath(dir_path, repo_root)
        return (False, f"âŒ å¤„ç†ç›®å½•{rel_path}å¤±è´¥: {str(e)[:50]}", None)


def process_single_file(file_path, repo_root, output_dir, formatter, output_format):
    """å¤„ç†éç›®æ ‡æ·±åº¦ç›®å½•ä¸­çš„å•ä¸ªæ–‡ä»¶"""
    try:
        # è·³è¿‡è¿‡å¤§æ–‡ä»¶
        file_size = os.path.getsize(file_path)
        if file_size > MAX_FILE_SIZE:
            rel_path = os.path.relpath(file_path, repo_root)
            return (False, f"â­ï¸ è·³è¿‡è¿‡å¤§æ–‡ä»¶ ({file_size//1024//1024}MB): {rel_path}")

        # è·å–ç›¸å¯¹è·¯å¾„
        rel_path = os.path.relpath(file_path, repo_root)

        # æ£€æŸ¥æ˜¯å¦åº”è¯¥è¢«å¿½ç•¥
        if should_ignore(rel_path) or should_ignore(file_path):
            if is_binary_file(file_path):
                return (False, f"ğŸ”‡ å¿½ç•¥äºŒè¿›åˆ¶æ–‡ä»¶: {rel_path}")
            else:
                return (False, f"ğŸ”‡ å¿½ç•¥æ–‡ä»¶: {rel_path}")

        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„
        file_name = os.path.basename(rel_path)
        new_file_name = f"{file_name}.{output_format}"
        output_rel_path = os.path.join(
            os.path.dirname(rel_path), new_file_name)
        output_path = os.path.join(output_dir, output_rel_path)
        output_path = shorten_long_path(
            output_path, MAX_PATH_LENGTH, output_format)

        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(os.path.dirname(output_path), exist_ok=True)

        # è¯»å–æ–‡ä»¶å†…å®¹
        content = read_file_content(file_path)

        # æ ¹æ®æ–‡ä»¶ç±»å‹å’Œè¾“å‡ºæ ¼å¼å¤„ç†å†…å®¹
        ext = os.path.splitext(file_path)[1].lower()
        file_ext = ext.lstrip('.') if ext else 'txt'

        if output_format == 'html':
            if ext == ".md":
                # è½¬æ¢Markdownä¸ºHTML
                html_content = markdown2.markdown(
                    content,
                    extras=["fenced-code-blocks", "tables"]
                )
                highlight_css = ""
            else:
                # è½¬æ¢ä»£ç æ–‡ä»¶ä¸ºå¸¦é«˜äº®çš„HTML
                try:
                    lexer = get_lexer_for_filename(file_path)
                except Exception:
                    lexer = TextLexer()
                html_content = highlight(content, lexer, formatter)
                highlight_css = formatter.get_style_defs(".highlight")

            # ä½¿ç”¨æ¨¡æ¿ç”Ÿæˆå®Œæ•´HTML
            final_content = file_template.render(
                title=rel_path,
                rel_path=rel_path,
                content=html_content,
                highlight_css=highlight_css
            )

        else:  # markdown
            if ext == ".md":
                # ä¿ç•™Markdownæ–‡ä»¶çš„åŸå§‹å†…å®¹ï¼Œæ·»åŠ æ ‡é¢˜
                final_content = f"# æ–‡ä»¶è·¯å¾„: {rel_path}\n\n{content}"
            else:
                # ç”ŸæˆMarkdownä»£ç å—
                try:
                    lexer = get_lexer_for_filename(file_path)
                    lexer_name = lexer.aliases[0] if lexer.aliases else lexer.name.lower()
                except Exception:
                    try:
                        lexer = get_lexer_by_name(file_ext)
                        lexer_name = file_ext
                    except Exception:
                        lexer_name = 'text'

                # è½¬ä¹‰ä»£ç ä¸­çš„åå¼•å·
                escaped_content = content.replace('`', '\\`')
                final_content = f"# æ–‡ä»¶è·¯å¾„: {rel_path}\n\n``` {lexer_name}\n{escaped_content}\n```\n"

        # å†™å…¥è¾“å‡ºæ–‡ä»¶
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(final_content)

        return (True, f"ğŸŸ¢ è½¬æ¢ä¸º{output_format}: {rel_path}")

    except Exception as e:
        rel_path = os.path.relpath(file_path, repo_root)
        return (False, f"âŒ å¤„ç†æ–‡ä»¶{rel_path}å¤±è´¥: {str(e)[:50]}")


def collect_files_and_dirs_to_process(repo_path):
    """æ”¶é›†æ‰€æœ‰éœ€è¦å¤„ç†çš„æ–‡ä»¶å’Œç›®æ ‡ç›®å½•"""
    target_dirs = collect_target_directories(repo_path)
    non_target_files = []
    stack = [repo_path]

    # æ ‡è®°æ‰€æœ‰ç›®æ ‡ç›®å½•ï¼Œé¿å…é‡å¤å¤„ç†å…¶æ–‡ä»¶
    target_dir_set = set(target_dirs.keys())

    while stack:
        current_dir = stack.pop()
        # å¦‚æœæ˜¯ç›®æ ‡ç›®å½•åˆ™è·³è¿‡
        if current_dir in target_dir_set:
            continue
            
        try:
            with os.scandir(current_dir) as entries:
                for entry in entries:
                    try:
                        if entry.is_dir(follow_symlinks=False):
                            if not should_ignore(entry.path):
                                stack.append(entry.path)
                        else:
                            if not should_ignore(entry.path):
                                non_target_files.append(entry.path)
                    except Exception as e:
                        click.echo(f"âš ï¸ è®¿é—®{entry.path}æ—¶å‡ºé”™: {str(e)[:30]}")
                        continue
        except PermissionError:
            click.echo(f"ğŸš« æ²¡æœ‰æƒé™è®¿é—®ç›®å½•: {current_dir}")
            continue
        except Exception as e:
            click.echo(f"âš ï¸ å¤„ç†ç›®å½•{current_dir}æ—¶å‡ºé”™: {str(e)[:30]}")
            continue

    click.echo(f"ğŸ“Š å‘ç°{len(non_target_files)}ä¸ªå¸¸è§„æ–‡ä»¶å’Œ{len(target_dirs)}ä¸ªç›®æ ‡æ·±åº¦ç›®å½•éœ€è¦å¤„ç†")
    return non_target_files, target_dirs, target_dir_set


def generate_index(repo_root, output_dir, repo_name, non_target_files, target_dirs, target_dir_set, output_format):
    """ç”Ÿæˆç›®å½•ç´¢å¼•é¡µ"""
    file_tree = {"__files__": [], "__dirs__": []}  # æ ¹èŠ‚ç‚¹åŒ…å«æ–‡ä»¶å’Œç›®å½•

    # æ·»åŠ å¸¸è§„æ–‡ä»¶
    for file_path in non_target_files:
        rel_path = os.path.relpath(file_path, repo_root)
        file_name = os.path.basename(rel_path)
        dir_path = os.path.dirname(rel_path)

        # æ„å»ºç›®å½•æ ‘ç»“æ„
        current_node = file_tree
        dir_parts = dir_path.split(os.sep) if dir_path != '.' else []

        for part in dir_parts:
            if not part:
                continue
            if part not in current_node:
                current_node[part] = {"__files__": [], "__dirs__": []}
            current_node = current_node[part]

        # æ·»åŠ æ–‡ä»¶ä¿¡æ¯
        output_file_name = f"{file_name}.{output_format}"
        output_rel_path = os.path.join(dir_path, output_file_name).replace(os.sep, "/")
        current_node["__files__"].append({
            "name": file_name,
            "url": output_rel_path,
            "formatted_name": output_file_name
        })

    # æ·»åŠ ç›®æ ‡ç›®å½•
    for dir_path, files_in_dir in target_dirs.items():
        rel_dir_path = os.path.relpath(dir_path, repo_root)
        dir_name = os.path.basename(rel_dir_path)
        parent_dir = os.path.dirname(rel_dir_path)

        # æ„å»ºç›®å½•æ ‘ç»“æ„
        current_node = file_tree
        dir_parts = parent_dir.split(os.sep) if parent_dir != '.' else []

        for part in dir_parts:
            if not part:
                continue
            if part not in current_node:
                current_node[part] = {"__files__": [], "__dirs__": []}
            current_node = current_node[part]

        # è®¡ç®—æ€»å¤§å°ä»¥ç¡®å®šæ˜¯å¦è¢«æ‹†åˆ†
        total_size = sum(size for _, size in files_in_dir if size <= MAX_FILE_SIZE)
        output_files = []
        
        # ç¡®å®šè¾“å‡ºæ–‡ä»¶å
        if total_size > MERGED_FILE_SIZE_LIMIT:
            # ä¼°è®¡åˆ†å—æ•°é‡ï¼ˆç²—ç•¥ä¼°è®¡ï¼‰
            estimated_parts = max(1, int(total_size / MERGED_FILE_SIZE_LIMIT) + 1)
            for i in range(1, estimated_parts + 1):
                output_file_name = f"{dir_name}_part{i}.{output_format}"
                output_rel_path = os.path.join(parent_dir, output_file_name).replace(os.sep, "/")
                output_files.append({
                    "name": f"{dir_name}_part{i}",
                    "url": output_rel_path,
                    "formatted_name": output_file_name
                })
        else:
            output_file_name = f"{dir_name}.{output_format}"
            output_rel_path = os.path.join(parent_dir, output_file_name).replace(os.sep, "/")
            output_files.append({
                "name": dir_name,
                "url": output_rel_path,
                "formatted_name": output_file_name
            })

        current_node["__dirs__"].append({
            "name": dir_name,
            "files": output_files
        })

    # ç”Ÿæˆä¸åŒæ ¼å¼çš„ç´¢å¼•æ–‡ä»¶
    try:
        if output_format == 'html':
            index_content = index_template.render(
                repo_name=repo_name,
                file_tree=file_tree,
                max_depth=MAX_DIRECTORY_DEPTH
            )
            index_filename = "index.html"
        else:  # markdown
            # ç”ŸæˆMarkdownæ ¼å¼ç›®å½•
            index_content = f"# {repo_name} æºä»£ç ç›®å½•\n\n"
            index_content += f"> è¯´æ˜: æ·±åº¦ä¸º{MAX_DIRECTORY_DEPTH}çš„ç›®å½•å·²åˆå¹¶å…¶æ‰€æœ‰å†…å®¹ï¼ˆåŒ…æ‹¬å­ç›®å½•ï¼‰\n\n"

            def add_directory_to_md(node, path="", level=1):
                content = ""
                # æ·»åŠ å­ç›®å½•
                for dir_name, dir_node in node.items():
                    if dir_name in ("__files__", "__dirs__"):
                        continue
                    new_path = f"{path}/{dir_name}" if path else dir_name
                    content += f"{'#' * (level + 1)} {dir_name}\n\n"
                    content += add_directory_to_md(dir_node, new_path, level + 1)

                # æ·»åŠ ç›®æ ‡ç›®å½•ï¼ˆå·²åˆå¹¶ï¼‰
                if "__dirs__" in node and node["__dirs__"]:
                    content += f"{'#' * (level + 1)} åˆå¹¶çš„ç›®æ ‡ç›®å½•\n\n"
                    for dir_item in node["__dirs__"]:
                        content += f"- {dir_item['name']}:\n"
                        for file in dir_item['files']:
                            content += f"  - [{file['name']}]({file['url']})\n"
                    content += "\n"

                # æ·»åŠ æ–‡ä»¶
                if "__files__" in node and node["__files__"]:
                    content += f"{'#' * (level + 1)} æ–‡ä»¶åˆ—è¡¨\n\n"
                    for file in node["__files__"]:
                        content += f"- [{file['name']}]({file['url']})\n"
                    content += "\n"
                return content

            index_content += add_directory_to_md(file_tree)
            index_filename = "index.md"

        index_path = os.path.join(output_dir, index_filename)
        with open(index_path, "w", encoding="utf-8") as f:
            f.write(index_content)
        click.echo(f"ğŸ  ç”Ÿæˆç›®å½•ç´¢å¼•: {index_path}")
    except Exception as e:
        click.echo(f"âŒ ç”Ÿæˆç›®å½•ç´¢å¼•å¤±è´¥: {str(e)}")


@click.command()
@click.option("--local-repo", required=True, help="æœ¬åœ°ä»“åº“è·¯å¾„ï¼ˆä¾‹å¦‚: ../qemuï¼‰")
@click.option("--output-dir", "-o", default=DEFAULT_OUTPUT_DIR, help="è¾“å‡ºç›®å½•ï¼Œé»˜è®¤ ./output")
@click.option("--output-format", "-f", type=click.Choice(['md','html']), default='md',
              help="è¾“å‡ºæ–‡ä»¶æ ¼å¼ï¼Œé€‰é¡¹: html, md, é»˜è®¤ md")
@click.option("--ignore", "-i", multiple=True, help="é¢å¤–çš„å¿½ç•¥æ¨¡å¼ï¼ˆå¯å¤šæ¬¡æŒ‡å®šï¼‰")
@click.option("--highlight-theme", default=HIGHLIGHT_THEME, help="ä»£ç é«˜äº®ä¸»é¢˜")
@click.option("--batch-size", default=BATCH_SIZE, help="æ¯æ‰¹å¤„ç†çš„æ–‡ä»¶æ•°é‡ï¼Œé»˜è®¤ 200")
@click.option("--max-workers", default=MAX_WORKERS, type=int,
              help=f"æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°ï¼Œé»˜è®¤è‡ªåŠ¨è°ƒæ•´ï¼ˆå½“å‰ç³»ç»Ÿæ¨è {get_optimal_workers()}ï¼‰")
@click.option("--max-file-size", default=MAX_FILE_SIZE//1024//1024, help="è·³è¿‡çš„æœ€å¤§æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰ï¼Œé»˜è®¤ 10")
@click.option("--max-depth", default=MAX_DIRECTORY_DEPTH, type=int,
              help=f"æœ€å†…å±‚æ–‡ä»¶å¤¹çš„æ·±åº¦ï¼Œæ­¤æ·±åº¦çš„æ–‡ä»¶å¤¹åŠå…¶æ‰€æœ‰å†…å®¹å°†è¢«åˆå¹¶ï¼Œé»˜è®¤ {MAX_DIRECTORY_DEPTH}")
def main(local_repo, output_dir, output_format, ignore, highlight_theme, batch_size, max_workers, max_file_size, max_depth):
    """å¤šçº¿ç¨‹æ‰¹é‡å¤„ç†æºä»£ç è½¬æ¢å·¥å…·ï¼Œæ”¯æŒæŒ‡å®šæœ€å†…å±‚ç›®å½•æ·±åº¦å¹¶åˆå¹¶å…¶æ‰€æœ‰å†…å®¹"""
    # æ›´æ–°å…¨å±€é…ç½®
    global HIGHLIGHT_THEME, IGNORE_PATTERNS, BATCH_SIZE, MAX_FILE_SIZE, MAX_WORKERS, MAX_DIRECTORY_DEPTH
    HIGHLIGHT_THEME = highlight_theme
    IGNORE_PATTERNS += list(ignore)
    BATCH_SIZE = batch_size
    MAX_FILE_SIZE = max_file_size * 1024 * 1024  # è½¬æ¢ä¸ºå­—èŠ‚
    MAX_WORKERS = max_workers if max_workers is not None else get_optimal_workers()
    MAX_DIRECTORY_DEPTH = max_depth
    click.echo(
        f"ğŸ”§ é…ç½®: æ¯æ‰¹å¤„ç†{batch_size}ä¸ªæ–‡ä»¶ï¼Œä½¿ç”¨{MAX_WORKERS}ä¸ªçº¿ç¨‹ï¼Œ"
        f"æœ€å†…å±‚ç›®å½•æ·±åº¦{MAX_DIRECTORY_DEPTH}ï¼Œåˆå¹¶æ–‡ä»¶å¤§å°é™åˆ¶{MERGED_FILE_SIZE_LIMIT/1024/1024:.1f}MiB"
    )

    # éªŒè¯ä»“åº“è·¯å¾„
    try:
        repo_path, repo_name = validate_local_repo(local_repo)
        click.echo(f"âœ… ä»“åº“éªŒè¯é€šè¿‡: {repo_path}")
    except Exception as e:
        click.error(f"âŒ ä»“åº“éªŒè¯å¤±è´¥: {e}")
        return

    # å‡†å¤‡è¾“å‡ºç›®å½•
    if os.path.exists(output_dir):
        click.echo(f"ğŸ§¹ æ¸…ç†æ—§è¾“å‡ºç›®å½•: {output_dir}")
        shutil.rmtree(output_dir, ignore_errors=True)
    os.makedirs(output_dir, exist_ok=True)

    # æ”¶é›†æ‰€æœ‰éœ€è¦å¤„ç†çš„æ–‡ä»¶å’Œç›®æ ‡ç›®å½•
    click.echo("\nğŸ” æ‰«æä»“åº“æ–‡ä»¶å’Œç›®å½•...")
    non_target_files, target_dirs, target_dir_set = collect_files_and_dirs_to_process(repo_path)
    if not non_target_files and not target_dirs:
        click.echo("â„¹ï¸ æ²¡æœ‰å¯å¤„ç†çš„æ–‡ä»¶æˆ–ç›®å½•")
        return

    # å¤šçº¿ç¨‹å¤„ç†æ–‡ä»¶å’Œç›®å½•
    click.echo(
        f"\nğŸ“„ å¼€å§‹å¤„ç†æ–‡ä»¶å’Œç›®å½•ï¼ˆæ‰¹å¤§å°{batch_size}ï¼Œ{MAX_WORKERS}ä¸ªå¹¶è¡Œçº¿ç¨‹ï¼Œè¾“å‡º{output_format}æ ¼å¼ï¼‰...")
    formatter = get_safe_formatter(highlight_theme, output_format)
    processed_count = 0
    total_items = len(non_target_files) + len(target_dirs)

    # å…ˆå¤„ç†ç›®æ ‡ç›®å½•
    if target_dirs:
        click.echo(f"\nğŸ“‚ å¼€å§‹å¤„ç†{len(target_dirs)}ä¸ªç›®æ ‡æ·±åº¦ç›®å½•...")
        dir_process_func = partial(
            process_target_directory,
            repo_root=repo_path,
            output_dir=output_dir,
            formatter=formatter,
            output_format=output_format
        )

        with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            futures = [executor.submit(dir_process_func, dir_path)
                       for dir_path in target_dirs.keys()]

            for future in concurrent.futures.as_completed(futures):
                success, message, _ = future.result()
                click.echo(message)
                if success:
                    processed_count += 1

        gc.collect()
        progress = (processed_count / total_items) * 100
        click.echo(f"ğŸ“Š è¿›åº¦: {processed_count}/{total_items} ({progress:.1f}%)")

    # ç„¶åå¤„ç†å¸¸è§„æ–‡ä»¶
    if non_target_files:
        click.echo(f"\nğŸ“„ å¼€å§‹å¤„ç†{len(non_target_files)}ä¸ªå¸¸è§„æ–‡ä»¶...")
        file_process_func = partial(
            process_single_file,
            repo_root=repo_path,
            output_dir=output_dir,
            formatter=formatter,
            output_format=output_format
        )

        for i in range(0, len(non_target_files), batch_size):
            # æ£€æŸ¥å†…å­˜ä½¿ç”¨æƒ…å†µ
            wait_for_memory()

            # è·å–å½“å‰æ‰¹æ¬¡æ–‡ä»¶
            batch_files = non_target_files[i:i+batch_size]
            batch_num = i // batch_size + 1
            click.echo(f"\nğŸ“¦ å¤„ç†æ‰¹æ¬¡{batch_num}ï¼ˆå…±{len(batch_files)}ä¸ªæ–‡ä»¶ï¼‰")

            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†å½“å‰æ‰¹æ¬¡
            with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
                results = executor.map(file_process_func, batch_files, chunksize=min(50, batch_size//MAX_WORKERS))
                
                for success, message in results:
                    click.echo(message)
                    if success:
                        processed_count += 1

            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            gc.collect()
            progress = (processed_count / total_items) * 100
            click.echo(f"ğŸ“Š è¿›åº¦: {processed_count}/{total_items} ({progress:.1f}%)")

    # ç”Ÿæˆç›®å½•ç´¢å¼•
    click.echo("\nğŸ“‹ ç”Ÿæˆç›®å½•ç´¢å¼•...")
    generate_index(repo_path, output_dir, repo_name,
                   non_target_files, target_dirs, target_dir_set, output_format)

    # å®Œæˆæ¶ˆæ¯
    click.echo(f"\nğŸ‰ æ‰€æœ‰å¤„ç†å®Œæˆ!")
    click.echo(f"ğŸ“Œ è¾“å‡ºç›®å½•: {os.path.abspath(output_dir)}")
    index_filename = "index.html" if output_format == 'html' else "index.md"
    click.echo(
        f"ğŸŒ ç´¢å¼•æ–‡ä»¶: file://{os.path.abspath(os.path.join(output_dir, index_filename))}")


# åˆå§‹åŒ–Jinja2æ¨¡æ¿ç¯å¢ƒï¼ˆä»…HTMLæ ¼å¼éœ€è¦ï¼‰
env = Environment(
    loader=FileSystemLoader(TEMPLATE_DIR),
    auto_reload=False,
    cache_size=0  # ç¦ç”¨æ¨¡æ¿ç¼“å­˜
)
file_template = env.get_template("file.html") if os.path.exists(
    os.path.join(TEMPLATE_DIR, "file.html")) else None
index_template = env.get_template("index.html") if os.path.exists(
    os.path.join(TEMPLATE_DIR, "index.html")) else None

if __name__ == "__main__":
    main()